---
title: "Experience"
---

## Experience

### Oncase — Recife, Brasil  
**Data Engineer** · Sep. 2025 – Dec. 2025

- **Document data extraction**  
  Enabled more reliable and accurate document understanding for the client’s product by improving how text is extracted from real-world documents, allowing the solution to adapt to data variability and continuously improve over time.  
  _Implemented using PaddlePaddleOCR._

- **Stack used**  
  Delivered the above solutions using a scalable orchestration and processing stack.  
  _Airflow orchestrating AWS ECS tasks on a daily schedule, with PaddlePaddleOCR for document text extraction._

---

### Acaso — Recife, Brazil  
**Data Scientist** · Jan. 2025 – Aug. 2025

- **Reliable data ingestion pipelines**  
  Reduced time spent on data ingestion issues and increased focus on model development by building stable, automated database pipelines for structured data.  
  _Implemented PostgreSQL ingestion handlers in Python using Psycopg2._

- **Retrieval-augmented generation systems**  
  Enabled accurate and context-aware information retrieval from large document collections, improving the quality of LLM responses for internal and client-facing use cases.  
  _Built RAG pipelines with LangChain and PostgreSQL VectorDB, generating embeddings from PDFs processed via Docling._

- **Rapid LLM prototyping**  
  Accelerated client feedback cycles by delivering interactive LLM-based prototypes early, allowing validation of use cases while preserving data privacy and database consistency.  
  _Developed LLM-based POCs using Streamlit and FastAPI._

- **Automated document ingestion**  
  Ensured timely and reliable data availability by automating document ingestion workflows, enabling teams to start each day with fresh, processed data ready for use.  
  _Scheduled ingestion pipelines using Apache Airflow. Saving about 6 hours weekly from working hours._

- **Cloud storage integration**  
  Reduced manual data handling and operational overhead by enabling seamless file ingestion and management, saving approximately 60% of the time previously spent on manual data preparation.  
  _Built AWS S3 integrations using Python and Boto3, supporting CLI and Streamlit-based execution._

---

### Di2win — Recife, Brazil  
**Data Scientist** · Jun. 2024 – Jan. 2025

- **Production ML data pipelines**  
  Enabled reliable machine learning in production by converting raw data into high-quality, versioned features that support training, validation, and inference across the full ML lifecycle.  
  _Built end-to-end ingestion, cleaning, and feature engineering workflows._

- **Model deployment and optimization**  
  Improved operational efficiency by deploying and continuously optimizing machine learning models tied to business KPIs, enabling strategic reordering of operations and reducing energy consumption by approximately 20%.  
  _Deployed regularized regression and LSTM time-series models, optimized with Optuna._

- **Automated training and retraining pipelines**  
  Accelerated experimentation and reduced manual overhead by automating training, retraining, and data refresh workflows, allowing models to adapt to new data or events without manual intervention.  
  _Implemented event-driven and scheduled pipelines using Apache Airflow._

- **ML reliability and production readiness**  
  Increased production stability and model trust by enforcing automated testing, validation, and deployment checks, resulting in fewer production incidents and safer releases.  
  _Implemented CI/CD pipelines with GitHub Actions and model/data tests using Pytest._

- **ML platform and delivery strategy**  
  Enabled fast and safe model delivery while protecting Di2win’s intellectual property by designing an ML platform that supports frequent retraining, continuous deployment, and parallel experimentation without disrupting active projects.  
  _Designed a scalable, isolated ML stack for rapid iteration._

---

### Valorian — Recife, Brazil  
**Data Scientist** · Apr. 2023 – Apr. 2024

- **Flexible data management**  
  Supported rapid product iteration by designing a data management approach that allows continuous processing and frequent changes without disrupting the system, giving the client freedom to refine and validate their MVP. Saving 30% of its budget adapting to the new format asked.  
  _Backed by a flexible data storage design._

- **Automated data processing workflows**  
  Reduced operational effort and improved reliability by automating end-to-end data ingestion and transformation, enabling the product to scale and evolve smoothly while saving approximately 30 hours of manual work per month.  
  _Automated using scheduled workflows and containerized tasks and reserved instances on AWS, saving about 20% to 25% per month on budget._

- **Interactive dashboards**  
  Developed dashboards using Dash Plotly for clients so they understand the storytelling behind the data they've provided.

- **Machine learning models optimized with Optuna**  
  Optimized XGBoost models, improving cost efficiency in wheat flour production by 12% by identifying the production orders that yield the greatest benefit.

## Highlights

- Impact-driven work
- Strong collaboration
- Continuous learning
